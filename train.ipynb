{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "import dataset.transforms as T\n",
    "\n",
    "from engine import *\n",
    "\n",
    "from dataset.coco_utils import get_coco, get_coco_kp\n",
    "from dataset.group_by_aspect_ratio import GroupedBatchSampler, create_aspect_ratio_groups\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = '../datasets/coco/'\n",
    "model_name = 'fasterrcnn_resnet50_fpn'\n",
    "dataset_name = 'coco'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 8\n",
    "epochs = 20\n",
    "workers = 8\n",
    "lr = 0.02\n",
    "momentum = 0.9\n",
    "weight_dacay = 1e-4\n",
    "print_freq = 20\n",
    "lr_step_size = 8\n",
    "lr_steps = [8, 11]\n",
    "lr_gamma = 0.1\n",
    "resume = ''\n",
    "test_only = True\n",
    "result_dir = './results'\n",
    "aspect_ratio_group_factor = 0\n",
    "pretrained = True\n",
    "distributed = False\n",
    "parallel = False\n",
    "world_size = 1\n",
    "dist_url = 'env://'\n",
    "mode = 'train'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_dataset(name, image_set, transforms=None):\n",
    "    print('Loading Data...')\n",
    "    paths = {'coco' : ('../datasets/coco/', get_coco, 91)}\n",
    "\n",
    "    p, ds_fn, num_classes = paths[name]\n",
    "\n",
    "    ds = ds_fn(p, image_set=image_set, transforms=transforms)\n",
    "    print('Loading Data Finished')\n",
    "    return ds, num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataloaders\n",
      "Loading Data...\n",
      "loading annotations into memory...\n",
      "Done (t=14.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading Data Finished\n",
      "Loading Data...\n",
      "loading annotations into memory...\n",
      "Done (t=1.68s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading Data Finished\n",
      "Using [0, 1.0, inf] as bins for aspect ratio quantization\n",
      "Count of instances per bin: [85308 31958]\n"
     ]
    }
   ],
   "source": [
    "#getting dataset - dataloader\n",
    "print('creating dataloaders')\n",
    "\n",
    "transforms = T.Compose([T.ToTensor(), T.RandomHorizontalFlip(0.5)])\n",
    "dataset_train, num_classes = get_dataset('coco', 'train', transforms=transforms)\n",
    "transforms = T.Compose([T.ToTensor()])\n",
    "dataset_val = get_dataset('coco', 'val', transforms=transforms)\n",
    "if distributed:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset_train)\n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(dataset_val)\n",
    "else:\n",
    "    train_sampler = torch.utils.data.RandomSampler(dataset_train)\n",
    "    val_sampler = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "if aspect_ratio_group_factor >= 0:\n",
    "    group_ids = create_aspect_ratio_groups(dataset_train, k=aspect_ratio_group_factor)\n",
    "    train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, batch_size)\n",
    "else:\n",
    "    train_batch_sampler = torch.utils.data.BatchSampler(train_sampler, batch_size, drop_last=True)\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_sampler=train_batch_sampler, num_workers=workers, collate_fn=utils.collate_fn)\n",
    "data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = batch_size, sampler=val_sampler, num_workers=workers, collate_fn=utils.collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_iou_types(model): #용도가뭐지???\n",
    "    model_without_ddp = model\n",
    "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model_without_ddp = model.module\n",
    "    iou_types = ['bbox']\n",
    "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
    "        iou_types.append('segm')\n",
    "    if isinstance(model_without_ddp, torchvision.models.KeypointRCNN):\n",
    "        iou_types.append('keypoints')\n",
    "    return iou_types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "start training\n"
     ]
    }
   ],
   "source": [
    "print('creating model')\n",
    "\n",
    "model = torchvision.models.detection.__dict__[model_name](num_classes=num_classes, pretrained=pretrained)\n",
    "device = torch.device(device)\n",
    "model.to(device)\n",
    "\n",
    "# # Distribute\n",
    "#     model_without_ddp = model\n",
    "#     if distributed:\n",
    "#         model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "#         model_without_ddp = model.module\n",
    "#\n",
    "#     # Parallel\n",
    "#     if parallel:\n",
    "#         print('Training parallel')\n",
    "#         model = torch.nn.DataParallel(model).cuda()\n",
    "#         model_without_ddp = model.module\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optim = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_dacay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optim, milestones=lr_steps, gamma=lr_gamma)\n",
    "\n",
    "if resume:\n",
    "    print('Resume training')\n",
    "    ckpt = torch.load(resume, map_location='cpu')\n",
    "    # model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "    optim.load_state_dict(ckpt['optim'])\n",
    "    lr_scheduler.load_state_dict(ckpt['lr_scheduler'])\n",
    "\n",
    "# if test_only:\n",
    "#     evaluate(model, data_loader_val, device=device)\n",
    "\n",
    "print('start training')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "st_epoch = 0\n",
    "\n",
    "for epoch in range(st_epoch,epochs):\n",
    "    train_one_epoch(model, optim, data_loader_train, device, epoch, print_freq)\n",
    "    #######\n",
    "    model.train()\n",
    "    loss_arr = []\n",
    "\n",
    "    warmup_lr_schedular = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader_train) - 1)\n",
    "\n",
    "        warmup_lr_scheduler = utils.warmup_lr_scheduler(optim, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in data_loader_train:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    loss_dict = model(images, targets)\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "    loss_arr += [losses]\n",
    "\n",
    "    optim.zero_grad()\n",
    "    losses.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if warmup_lr_scheduler is not None:\n",
    "        warmup_lr_scheduler.step()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    print('Losses Train {}'.format(loss_arr))\n",
    "    #val\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_arr = []\n",
    "\n",
    "        coco = get_coco_api_from_dataset(data_loader_val.dataset)\n",
    "        iou_types = _get_iou_types(model)\n",
    "        coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "        for image, targets, in data_loader_val:\n",
    "            image = list(img.to(device) for img in image)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            outputs = model(image)\n",
    "\n",
    "            outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "\n",
    "            res = {target['image_id'].item(): output for target, output in zip(targets, outputs)}\n",
    "\n",
    "            coco_evaluator.update(res)\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_arr += [losses]\n",
    "        print('Losses Val {}'.format(loss_arr))\n",
    "        \n",
    "\n",
    "    #########\n",
    "\n",
    "    if result_dir and epoch % 10 == 0:\n",
    "        utils.save_on_master({\n",
    "            # 'model': model_without_ddp.state_dict(),\n",
    "            'optimizer': optim.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict()\n",
    "        },\n",
    "        os.path.join(result_dir, 'model_{}.pth'.format(epoch)))\n",
    "    evaluate(model, data_loader_val, device=device)\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}